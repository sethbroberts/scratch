{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random, re, pathlib, os\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    data = []\n",
    "    emaildir = pathlib.Path.cwd() / 'emails'\n",
    "    for dirpath, dirs, files in os.walk(emaildir, topdown=False):\n",
    "        is_spam = 'spam' in dirpath\n",
    "        for file in files:\n",
    "            with open(pathlib.Path(dirpath) / file, 'rb') as email:\n",
    "                for line in email:\n",
    "                    line = line.decode('utf-8', 'ignore')\n",
    "                    if line.startswith('Subject:'):\n",
    "                        line = line.replace('Subject:', '')\n",
    "                        line = line.strip()\n",
    "                        data.append((line, is_spam))\n",
    "                        break\n",
    "    return data\n",
    "    \n",
    "    \n",
    "def split(data, split_fraction=0.7):\n",
    "    shuffled_data = random.sample(data, k=len(data))\n",
    "    split_ix = int(split_fraction * len(data))\n",
    "    return shuffled_data[:split_ix], shuffled_data[split_ix:]\n",
    "    \n",
    "    \n",
    "def counts(data):\n",
    "    cts = Counter([label for _, label in data])\n",
    "    return cts[True], cts[False]\n",
    "    \n",
    "    \n",
    "def tokenize(message):\n",
    "    message = message.lower()\n",
    "    words = re.findall(r\"([a-z0-9']+)\", message)\n",
    "    return set(words)\n",
    "    \n",
    "    \n",
    "def word_counts(data):\n",
    "    wcounts = defaultdict(lambda: [0,0])\n",
    "    for message, is_spam in data:\n",
    "        words = tokenize(message)\n",
    "        for word in words:\n",
    "            wcounts[word][0 if is_spam else 1] += 1\n",
    "    return wcounts\n",
    "    \n",
    "    \n",
    "def word_probabilities(wcounts, tot_spam, tot_nonspam, k=0.5):\n",
    "    # word, p(word | spam), p(word | nonspam)\n",
    "    # laplace smoothing\n",
    "    return [\n",
    "        (word, (ct_spam + k)/(tot_spam + 2*k), (ct_nonspam + k)/(tot_nonspam + 2*k))\n",
    "        for word, (ct_spam, ct_nonspam) in wcounts.items()\n",
    "    ]\n",
    "    \n",
    "    \n",
    "def nbclassify(wprobs, message, prior_spam, prior_nonspam):\n",
    "    # p(spam | message) = \n",
    "    #      p(message | spam)*p(spam) / \n",
    "    #           [p(message | spam)*p(spam) + p(message | nonspam)*p(nonspam)]\n",
    "    log_prob_spam = log_prob_nonspam = 0.0\n",
    "    message_words = tokenize(message)\n",
    "    for word, pspam, pnonspam in wprobs:\n",
    "        if word in message_words:\n",
    "            log_prob_spam += math.log(pspam)\n",
    "            log_prob_nonspam += math.log(pnonspam)\n",
    "        else:\n",
    "            log_prob_spam += math.log(1-pspam)\n",
    "            log_prob_nonspam += math.log(1-pnonspam)\n",
    "    prob_spam = math.exp(log_prob_spam)\n",
    "    prob_nonspam = math.exp(log_prob_nonspam)\n",
    "    return (prob_spam * prior_spam) / ((prob_spam * prior_spam) + (prob_nonspam * prior_nonspam))\n",
    "    \n",
    "    \n",
    "def runtest(wprobs, test, prior_spam=0.5, prior_nonspam=0.5):\n",
    "    results = []\n",
    "    for message, is_spam in test:\n",
    "        pspam = nbclassify(wprobs, message, prior_spam=0.5, prior_nonspam=0.5)\n",
    "        results.append((is_spam, pspam >=0.5))\n",
    "    return Counter(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(False, False): 818,\n",
       "         (False, True): 27,\n",
       "         (True, False): 45,\n",
       "         (True, True): 100})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_data()\n",
    "train, test = split(data)\n",
    "tot_spam, tot_nonspam = counts(train)\n",
    "wcounts = word_counts(train)\n",
    "wprobs = word_probabilities(wcounts, tot_spam, tot_nonspam)\n",
    "runtest(wprobs, test, prior_spam=0.5, prior_nonspam=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
